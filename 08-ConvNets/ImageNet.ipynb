{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "from time import time\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import clear_output\n",
    "import argparse\n",
    "import sys\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92b58ec4db7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mValDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "class ValDataset(Dataset):\n",
    "    def __init__(self, csv_file, root, transform=None):\n",
    "        self.info = pd.read_csv(csv_file, sep='\\t', header=None)\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        classes = pd.read_csv('tiny-imagenet-200/wnids.txt', sep='\\t', header=None).sort_values(0).reset_index(drop=True)\n",
    "        self.classes_dict = {classes[0][i]:i for i in range(200)} # class id to class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root, self.info.iloc[idx, 0])\n",
    "        image = np.asarray(Image.open(img_name).convert('RGB'))\n",
    "        target = self.classes_dict[self.info.iloc[idx, 1]]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Accuracy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Accuracy, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        return torch.mean((preds == targets).double())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValDataset(Dataset):\n",
    "    def __init__(self, csv_file, root, transform=None):\n",
    "        self.info = pd.read_csv(csv_file, sep='\\t', header=None)\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        classes = pd.read_csv('tiny-imagenet-200/wnids.txt', sep='\\t', header=None).sort_values(0).reset_index(drop=True)\n",
    "        self.classes_dict = {classes[0][i]:i for i in range(200)} # class id to class\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.info)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root, self.info.iloc[idx, 0])\n",
    "        image = np.asarray(Image.open(img_name).convert('RGB'))\n",
    "        target = self.classes_dict[self.info.iloc[idx, 1]]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "class Accuracy(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Accuracy, self).__init__()\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        return torch.mean((preds == targets).double())\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, metric, device, optimizer, eff_batch_size=512, checkpoint_seg=3):\n",
    "    total_loss = 0\n",
    "    total_acc  = 0\n",
    "    n = len(dataloader)    \n",
    "    \n",
    "    #accumulating batches\n",
    "    effective_batch_size = eff_batch_size\n",
    "    loader_batch_size = dataloader.batch_size\n",
    "    batches_per_update = effective_batch_size / loader_batch_size\n",
    "    \n",
    "    model.train(True)\n",
    "    for i_batch, (X_batch, y_batch) in enumerate(dataloader):\n",
    "        \n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        #checkpointing\n",
    "        if checkpoint_seg == 0:\n",
    "            out = model(X_batch)\n",
    "        else:\n",
    "            X_batch.requires_grad = True\n",
    "            out = checkpoint_sequential(model, checkpoint_seg, X_batch)\n",
    "\n",
    "        loss = criterion(out, y_batch)\n",
    "        loss.backward()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        total_acc += metric(out, y_batch).item()\n",
    "\n",
    "        #accumulating gradients\n",
    "        if (i_batch + 1) % batches_per_update == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "    av_loss = total_loss / n\n",
    "    av_acc  = total_acc  / n\n",
    "\n",
    "    return av_loss, av_acc\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_model(model, dataloader, criterion, metric, device):\n",
    "    total_acc = 0\n",
    "    total_loss = 0\n",
    "    n = len(dataloader)  \n",
    "    \n",
    "    model.eval()\n",
    "    for X_batch, y_batch in dataloader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        out = model(X_batch)\n",
    "        total_loss +=criterion(out, y_batch)\n",
    "        total_acc += metric(out, y_batch).item()\n",
    "\n",
    "    av_acc  = total_acc / n\n",
    "    av_loss = total_loss / n\n",
    "\n",
    "    return av_loss, av_acc\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, optimizer,\n",
    "                criterion=nn.CrossEntropyLoss(), \n",
    "                metric=Accuracy(), \n",
    "                device=torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu'), \n",
    "                epochs=50,\n",
    "                max_acc=0.4,\n",
    "                eff_batch_size=128,\n",
    "                checkpoint_seg=3):\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    model = model.to(device)\n",
    "    log_acc = []\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_start = time.time()\n",
    "        loss, train_acc = train_epoch(model, dataloaders['train'], criterion, metric, device, \n",
    "                                      optimizer, eff_batch_size, checkpoint_seg)   \n",
    "        train_time = time.time() - train_start\n",
    "\n",
    "        val_loss, val_acc  =  eval_model(model, dataloaders['val'],  criterion, metric, device)\n",
    "        test_loss, test_acc =  eval_model(model, dataloaders['test'], criterion, metric, device)\n",
    "        \n",
    "        log_acc.append((train_acc, val_acc, test_acc, loss, val_loss, test_loss))\n",
    "        \n",
    "        draw_accuracy(log_acc)\n",
    "\n",
    "        print(\"Epoch [{}/{}] Time: {:.2f}s; BF Time: {:.2f}s; TrainLoss: {:.4f}; TrainAccuracy: {:.4f}; ValAccuracy: {:.4f}, TestAccuracy: {:.4f}\".format(\n",
    "              epoch + 1, epochs, time.time() - start_time, train_time, loss, train_acc, val_acc, test_acc))    \n",
    "\n",
    "        if test_acc > max_acc:\n",
    "            break\n",
    "    \n",
    "    print(\"Full_time: {:.2f}s\".format(time.time() - start))\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"Peak memory usage by Pytorch tensors: {(torch.cuda.max_memory_allocated() / 1024 / 1024):.2f} Mb\")\n",
    "\n",
    "    return model, val_acc, test_acc\n",
    "\n",
    "\n",
    "def block(cin, cout, kernel_size=(3,3), padding=(1,1), stride=(1,1), pool_size=(2,2)):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=cin, \n",
    "                  out_channels=cout, \n",
    "                  kernel_size=kernel_size, \n",
    "                  padding=padding, \n",
    "                  stride=stride),\n",
    "        nn.BatchNorm2d(num_features=cout),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.MaxPool2d(kernel_size=pool_size)\n",
    "    )\n",
    "\n",
    "def get_model(cin=3, cout=200, base=64, drop=0.2):\n",
    "    return torch.nn.Sequential(\n",
    "        block(cin=cin, \n",
    "              cout=base),\n",
    "        block(cin=base, \n",
    "              cout=base*2),\n",
    "        nn.Dropout(0.2),\n",
    "        block(cin=base*2, \n",
    "              cout=base*4),\n",
    "        block(cin=base*4, \n",
    "              cout=base*8),\n",
    "        nn.Flatten(),\n",
    "        nn.Dropout(drop),\n",
    "        nn.Linear(in_features=base*8*4*4, \n",
    "                  out_features=base*16),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(drop),\n",
    "        nn.Linear(in_features=base*16, \n",
    "                  out_features=cout)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_data(batch_size=64):\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(64, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomAffine(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transform_train)\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [80000, 20000])\n",
    "    test_dataset  = ValDataset(csv_file='tiny-imagenet-200/val/val_annotations.txt',\n",
    "                              root='tiny-imagenet-200/val/images',   \n",
    "                              transform=transform_test)\n",
    "    \n",
    "\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8),\n",
    "        'val'  : DataLoader(val_dataset,   batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "        'test' : DataLoader(test_dataset,  batch_size=batch_size, shuffle=True, num_workers=4) \n",
    "    }\n",
    "\n",
    "    return dataloaders\n",
    "\n",
    "\n",
    "def create_parser():\n",
    "    pars = argparse.ArgumentParser()\n",
    "    pars.add_argument('-batch_size',\n",
    "                      help=\"choose batch size\", type=int, default=64)\n",
    "    pars.add_argument('-eff_batch_size',\n",
    "                      help=\"choose effective batch size\", type=int, default=512)\n",
    "    pars.add_argument('-drop',\n",
    "                      help=\"dropout in model \", type=float, default=0.2)\n",
    "    pars.add_argument('-base',\n",
    "                      help=\"base in model \", type=int, default=64)\n",
    "    pars.add_argument('-checkpoint_count',\n",
    "                      help=\"count of checkpoints\", type=int, default=10)\n",
    "    pars.add_argument('-epoch',\n",
    "                      help=\"choose number of epoch\", type=int, default=50)\n",
    "    pars.add_argument('-max_acc',\n",
    "                      help=\"choose what test accuracy is enought\", type=float, default=0.4)\n",
    "    pars.add_argument('-lr',\n",
    "                      help=\"adam learning rate\", type=float, default=0.001)\n",
    "    pars.add_argument('-save',\n",
    "                      help=\"save model\", type=bool, default=True)\n",
    "\n",
    "    return pars\n",
    "\n",
    "def main(batch_size, lr, epoch, max_acc, eff_batch_size, checkpoint_count, drop, base, save):\n",
    "    \n",
    "    model = get_model(base=base, drop=drop)\n",
    "\n",
    "    dataloaders = get_data(batch_size=batch_size)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "\n",
    "    trained_model, val_accuracy, test_accuracy = train_model(model=model, \n",
    "                                                             dataloaders=dataloaders, \n",
    "                                                             optimizer=optimizer, \n",
    "                                                             epochs=epoch,\n",
    "                                                             max_acc=max_acc,\n",
    "                                                             eff_batch_size=eff_batch_size,\n",
    "                                                             checkpoint_seg=checkpoint_count)\n",
    "    \n",
    "    if save:\n",
    "        torch.save(trained_model.state_dict(), 'model_state.pt')\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     parser = create_parser()\n",
    "#     namespace = parser.parse_args(sys.argv[1:])\n",
    "#     print(vars(namespace))\n",
    "#     main(**vars(namespace))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
