{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kXqsuXifjO_1"
   },
   "source": [
    "# Large scale text analysis with deep learning (3 points)\n",
    "\n",
    "Today we're gonna apply the newly learned tools for the task of predicting job salary.\n",
    "\n",
    "\n",
    "_Special thanks to [Oleg Vasilev](https://github.com/Omrigan/) for the core assignment idea._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1BBGiQ3NjO_5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nJIjp3LHjPAF"
   },
   "source": [
    "### About the challenge\n",
    "For starters, let's download and unpack the data from [here](https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=0). \n",
    "\n",
    "You can also get it from [yadisk url](https://yadi.sk/d/vVEOWPFY3NruT7) the competition [page](https://www.kaggle.com/c/job-salary-prediction/data) (pick `Train_rev1.*`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "B5CAcqHrjPAH",
    "outputId": "c22978ec-1206-40e5-e917-f8a69925be21"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  119M  100  119M    0     0  15.2M      0  0:00:07  0:00:07 --:--:-- 22.2M\n",
      "Train_rev1.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!curl -L https://www.dropbox.com/s/5msc5ix7ndyba10/Train_rev1.csv.tar.gz?dl=1 -o Train_rev1.csv.tar.gz\n",
    "!tar -xvzf ./Train_rev1.csv.tar.gz\n",
    "data = pd.read_csv(\"./Train_rev1.csv\", index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEKuxBfBjPAQ"
   },
   "source": [
    "One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.\n",
    "\n",
    "There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.\n",
    "\n",
    "_You can read more [in the official description](https://www.kaggle.com/c/job-salary-prediction#description)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244768, 12)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"~/salary/Train_rev1.csv\", index_col=None)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "_oI9HA57jPAT",
    "outputId": "ad660e15-ace0-4fb0-9cbf-5a5be8780cc2"
   },
   "outputs": [],
   "source": [
    "data['Log1pSalary'] = np.log1p(data['SalaryNormalized']).astype('float32')\n",
    "\n",
    "plt.figure(figsize=[8, 4])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data[\"SalaryNormalized\"], bins=20);\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(data['Log1pSalary'], bins=20);\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hF4Z0R_MjPAZ"
   },
   "source": [
    "Our task is to predict one number, __Log1pSalary__.\n",
    "\n",
    "To do so, our model can access a number of features:\n",
    "* Free text: __`Title`__ and  __`FullDescription`__\n",
    "* Categorical: __`Category`__, __`Company`__, __`LocationNormalized`__, __`ContractType`__, and __`ContractTime`__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "I912vr-PjPAa",
    "outputId": "456727c3-3279-4e37-955b-bfb83c4a4b94"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>FullDescription</th>\n",
       "      <th>LocationRaw</th>\n",
       "      <th>LocationNormalized</th>\n",
       "      <th>ContractType</th>\n",
       "      <th>ContractTime</th>\n",
       "      <th>Company</th>\n",
       "      <th>Category</th>\n",
       "      <th>SalaryRaw</th>\n",
       "      <th>SalaryNormalized</th>\n",
       "      <th>SourceName</th>\n",
       "      <th>Log1pSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16802</th>\n",
       "      <td>66901706</td>\n",
       "      <td>Assistant Manager</td>\n",
       "      <td>ASSISTANT MANAGER PERMANENT  Up to **** PER AN...</td>\n",
       "      <td>Newcastle upon Tyne, North East</td>\n",
       "      <td>Newcastle Upon Tyne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permanent</td>\n",
       "      <td>McCarthy Recruitment</td>\n",
       "      <td>Retail Jobs</td>\n",
       "      <td>16000 - 18000/annum</td>\n",
       "      <td>17000</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>9.741028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147366</th>\n",
       "      <td>70757869</td>\n",
       "      <td>Accounts Assistant</td>\n",
       "      <td>My client is looking for someone to join them ...</td>\n",
       "      <td>Wembley, Greater London, England, Middlesex</td>\n",
       "      <td>London</td>\n",
       "      <td>NaN</td>\n",
       "      <td>contract</td>\n",
       "      <td>Interaction Recruitment</td>\n",
       "      <td>Accounting &amp; Finance Jobs</td>\n",
       "      <td>7/hour</td>\n",
       "      <td>13440</td>\n",
       "      <td>cv-library.co.uk</td>\n",
       "      <td>9.506065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108618</th>\n",
       "      <td>69618603</td>\n",
       "      <td>Domiciliary Care Manager Gloucestershire  Chel...</td>\n",
       "      <td>An experienced, organised and qualitydriven Do...</td>\n",
       "      <td>Cheltenham</td>\n",
       "      <td>Cheltenham</td>\n",
       "      <td>full_time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Service Care Solutions</td>\n",
       "      <td>Healthcare &amp; Nursing Jobs</td>\n",
       "      <td>28,000 - 30,000/Year</td>\n",
       "      <td>29000</td>\n",
       "      <td>staffnurse.com</td>\n",
       "      <td>10.275085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  ... Log1pSalary\n",
       "16802   66901706  ...    9.741028\n",
       "147366  70757869  ...    9.506065\n",
       "108618  69618603  ...   10.275085\n",
       "\n",
       "[3 rows x 13 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_columns = [\"Title\", \"FullDescription\"]\n",
    "categorical_columns = [\"Category\", \"Company\", \"LocationNormalized\", \"ContractType\", \"ContractTime\"]\n",
    "target_column = \"Log1pSalary\"\n",
    "\n",
    "data[categorical_columns] = data[categorical_columns].fillna('NaN') # cast missing values to string \"NaN\"\n",
    "\n",
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kOd8m1F8jPAi"
   },
   "source": [
    "### Preprocessing text data\n",
    "\n",
    "Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).\n",
    "\n",
    "__Your task__ is to lowercase and tokenize all texts under `Title` and `FullDescription` columns. Store the tokenized data as a __space-separated__ string of tokens for performance reasons.\n",
    "\n",
    "It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "4GoQiv6mjPAk",
    "outputId": "3d3c6f77-6132-4731-de0a-a6b20bec68f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text:\n",
      "2         Mathematical Modeller / Simulation Analyst / O...\n",
      "100002    A successful and high achieving specialist sch...\n",
      "200002    Web Designer  HTML, CSS, JavaScript, Photoshop...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw text:\")\n",
    "print(data[\"FullDescription\"][2::100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1cPHRhrfjPAq"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "\n",
    "# see task above\n",
    "data['FullDescription'] = data['FullDescription'].apply(str).apply(str.lower).apply(tokenizer.tokenize).apply(' '.join)\n",
    "data['Title'] = data['Title'].apply(str).apply(str.lower).apply(tokenizer.tokenize).apply(' '.join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMHeUXPRjPAx"
   },
   "source": [
    "Now we can assume that our text is a space-separated list of tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "ZRg3mO81jPAy",
    "outputId": "a1c39a50-720f-4b2b-c5c9-a7950212e1f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized:\n",
      "2         mathematical modeller / simulation analyst / o...\n",
      "100002    a successful and high achieving specialist sch...\n",
      "200002    web designer html , css , javascript , photosh...\n",
      "Name: FullDescription, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokenized:\")\n",
    "print(data[\"FullDescription\"][2::100000])\n",
    "assert data[\"FullDescription\"][2][:50] == 'mathematical modeller / simulation analyst / opera'\n",
    "assert data[\"Title\"][54321] == 'international digital account manager ( german )'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSdbnnmmjPA3"
   },
   "source": [
    "Not all words are equally useful. Some of them are typos or rare words that are only present a few times. \n",
    "\n",
    "Let's count how many times is each word present in the data so that we can build a \"white list\" of known words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9T-DdZz-jPA5"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# Count how many times does each token occur in both \"Title\" and \"FullDescription\" in total\n",
    "# build a dictionary { token -> it's count }\n",
    "token_counts = Counter(token for col in text_columns\n",
    "                             for item in data[col]\n",
    "                             for token in item.split())\n",
    "\n",
    "# hint: you may or may not want to use collections.Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "Wrrz-aSyjPA-",
    "outputId": "f3e9e470-cdd9-441b-843c-441f550611d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 202704\n",
      "('and', 2657388)\n",
      "('.', 2523216)\n",
      "(',', 2318606)\n",
      "('the', 2080994)\n",
      "('to', 2019884)\n",
      "...\n",
      "('stephanietraveltraderecruitmnt', 1)\n",
      "('ruabon', 1)\n",
      "('lowehays', 1)\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))\n",
    "\n",
    "assert token_counts.most_common(1)[0][1] in  range(2600000, 2700000)\n",
    "assert len(token_counts) in range(200000, 210000)\n",
    "print('Correct!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "d0baFhfNjPBE",
    "outputId": "e31b6e37-6833-4d75-b1ca-7c6683f052d8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEKCAYAAAAcgp5RAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Word counts\");\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cpU22q5-jPBJ"
   },
   "source": [
    "Now filter tokens a list of all tokens that occur at least 10 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzfHYHr7jPBK"
   },
   "outputs": [],
   "source": [
    "min_count = 10\n",
    "\n",
    "# tokens from token_counts keys that had at least min_count occurrences throughout the dataset\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "43S1WfpMjPBQ",
    "outputId": "929a45fd-9571-4dbe-9c77-c4906f4d7353"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34156"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "TsbLDC1VjPBU",
    "outputId": "653e8641-1901-430b-92e0-9a7226644dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 34158\n",
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))\n",
    "\n",
    "assert type(tokens) == list\n",
    "assert len(tokens) in range(30000, 40000)\n",
    "assert 'me' in tokens\n",
    "assert UNK in tokens\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "toHEu5Q7jPBZ"
   },
   "source": [
    "Build an inverse token index: a dictionary from token(string) to it's index in `tokens` (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sd9zLe4ojPBb"
   },
   "outputs": [],
   "source": [
    "token_to_id = dict((tokens[i], i) for i in range(len(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "d8EzNYwijPBg",
    "outputId": "680da451-f49d-4734-e812-a6491c7fe0cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34158, 34158)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_to_id), len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WBGI258SjPBj",
    "outputId": "63624eb5-b321-4f53-dd9c-077fb68c2ee5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "assert isinstance(token_to_id, dict)\n",
    "assert len(token_to_id) == len(tokens)\n",
    "for tok in tokens:\n",
    "    assert tokens[token_to_id[tok]] == tok\n",
    "\n",
    "print(\"Correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2r6myI6jPBq"
   },
   "source": [
    "And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYHKucFRjPBr"
   },
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\" Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "    \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "Vt8GROZPjPBv",
    "outputId": "ed303e59-a1a0-44df-fc91-24e5e5dbb87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "engineering systems analyst\n",
      "hr assistant\n",
      "senior ec & i engineer\n",
      "\n",
      "Matrix:\n",
      "[[10807 30161  2166     1     1]\n",
      " [15020  2844     1     1     1]\n",
      " [27645 10201    16 15215 10804]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(data[\"Title\"][::100000].values), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(data[\"Title\"][::100000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d19BCr_djPB0"
   },
   "source": [
    "Now let's  encode the categirical data we have.\n",
    "\n",
    "As usual, we shall use one-hot encoding for simplicity. Kudos if you implement more advanced encodings: tf-idf, pseudo-time-series, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "_Y24w71mjPB1",
    "outputId": "72de013b-c886-4904-ebe8-dfaa8c9817c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "               sparse=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# we only consider top-1k most frequent companies to minimize memory usage\n",
    "top_companies, top_counts = zip(*Counter(data['Company']).most_common(1000))\n",
    "recognized_companies = set(top_companies)\n",
    "data[\"Company\"] = data[\"Company\"].apply(lambda comp: comp if comp in recognized_companies else \"Other\")\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(data[categorical_columns].apply(dict, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cPK5tfhpjPB5"
   },
   "source": [
    "### The deep learning part\n",
    "\n",
    "Once we've learned to tokenize the data, let's design a machine learning experiment.\n",
    "\n",
    "As before, we won't focus too much on validation, opting for a simple train-test split.\n",
    "\n",
    "__To be completely rigorous,__ we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VH5mp5PUjPB7",
    "outputId": "78ed02dd-7298-40c6-99c9-a922dfbe3e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  195814\n",
      "Validation size =  48954\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_val = train_test_split(data, test_size=0.2, random_state=42)\n",
    "data_train.index = range(len(data_train))\n",
    "data_val.index = range(len(data_val))\n",
    "\n",
    "print(\"Train size = \", len(data_train))\n",
    "print(\"Validation size = \", len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UAB54UzSjPB-"
   },
   "outputs": [],
   "source": [
    "def make_batch(data, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    :param word_dropout: replaces token index with UNK_IX with this probability\n",
    "    :returns: a dict with {'title' : int64[batch, title_max_len]\n",
    "    \"\"\"\n",
    "    batch = {}\n",
    "    batch[\"Title\"] = as_matrix(data[\"Title\"].values, max_len)\n",
    "    batch[\"FullDescription\"] = as_matrix(data[\"FullDescription\"].values, max_len)\n",
    "    batch['Categorical'] = categorical_vectorizer.transform(data[categorical_columns].apply(dict, axis=1))\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"FullDescription\"] = apply_word_dropout(batch[\"FullDescription\"], 1. - word_dropout)\n",
    "    \n",
    "    if target_column in data.columns:\n",
    "        batch[target_column] = data[target_column].values\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX,):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "9HWEnxePjPCC",
    "outputId": "9cde765e-9a98-4a5a-eebf-9986b1b30f76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Categorical': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " 'FullDescription': array([[27645, 29893, 33674, 32939,   982, 27645, 29893, 33674, 16451,\n",
       "         32939],\n",
       "        [29239,   197, 19175, 20042, 15554, 23162,  4051, 25511,   907,\n",
       "            82],\n",
       "        [30746, 21956, 20601,  6409, 16451,  8165, 27493,   982, 30412,\n",
       "         17746]], dtype=int32),\n",
       " 'Log1pSalary': array([ 9.71154 , 10.463132, 10.71444 ], dtype=float32),\n",
       " 'Title': array([[27645, 29893, 33674,     1,     1,     1,     1],\n",
       "        [29239,   197, 19175, 20042, 15554, 23162,  4051],\n",
       "        [10609, 30412, 17746,    33,  8705, 29157,    65]], dtype=int32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_batch(data_train[:3], max_len=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRgpu---jPCG"
   },
   "source": [
    "#### Architecture\n",
    "\n",
    "Our basic model consists of three branches:\n",
    "* Title encoder\n",
    "* Description encoder\n",
    "* Categorical features encoder\n",
    "\n",
    "We will then feed all 3 branches into one common network that predicts salary.\n",
    "\n",
    "<img src=\"https://github.com/yandexdataschool/nlp_course/raw/master/resources/w2_conv_arch.png\" width=600px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdgiPLeTjPCI"
   },
   "source": [
    "This clearly doesn't fit into keras' __Sequential__ interface. To build such a network, one will have to use __[Keras Functional API](https://keras.io/models/model/)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zo8TMj_jPCJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.models import Model, Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-HGS4I4MjPCS"
   },
   "outputs": [],
   "source": [
    "def build_model(n_tokens=len(tokens), n_cat_features=len(categorical_vectorizer.vocabulary_), hid_size=64):\n",
    "    \"\"\" Build a model that maps three data sources to a single linear output: predicted log1p(salary) \"\"\"\n",
    "    \n",
    "    l_title = L.Input(shape=[None], name=\"Title\")\n",
    "    l_descr = L.Input(shape=[None], name=\"FullDescription\")\n",
    "    l_categ = L.Input(shape=[n_cat_features], name=\"Categorical\")\n",
    "    \n",
    "    seq = Sequential([\n",
    "            L.Embedding(input_dim = n_tokens, \n",
    "                        output_dim = hid_size,\n",
    "                        name='Emb'),\n",
    "            L.Conv1D(filters=hid_size, \n",
    "                     kernel_size=(3,), \n",
    "                     activation='relu',\n",
    "                     name='Conv'),\n",
    "            L.GlobalMaxPool1D(name='Pool')\n",
    "        ])\n",
    "    \n",
    "    fir = seq(l_title)\n",
    "    sec = seq(l_descr)\n",
    "    \n",
    "    thi = L.Dense(hid_size)(l_categ)\n",
    "    \n",
    "    out = L.Dense(1)(L.Dense(128)(L.Concatenate()([fir, sec, thi])))\n",
    "\n",
    "    \n",
    "    model = Model(inputs=[l_title, l_descr, l_categ], outputs=[out])\n",
    "    model.compile('adam', 'mean_squared_error', metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "Xl_RF2kZjPCW",
    "outputId": "2696ab7b-a8f8-4fe2-91ea-ce3f996d191c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Title (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FullDescription (InputLayer)    [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Categorical (InputLayer)        [(None, 3768)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential (Sequential)         (None, 64)           2198464     Title[0][0]                      \n",
      "                                                                 FullDescription[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 64)           241216      Categorical[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 192)          0           sequential[1][0]                 \n",
      "                                                                 sequential[2][0]                 \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          24704       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,464,513\n",
      "Trainable params: 2,464,513\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "dummy_pred = model.predict(make_batch(data_train[:100]))\n",
    "dummy_loss = model.train_on_batch(make_batch(data_train[:100]), data_train['Log1pSalary'][:100])[0]\n",
    "assert dummy_pred.shape == (100, 1)\n",
    "assert len(np.unique(dummy_pred)) > 20, \"model returns suspiciously few unique outputs. Check your initialization\"\n",
    "assert np.ndim(dummy_loss) == 0 and 0. <= dummy_loss <= 250., \"make sure you minimize MSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hnQpLYJCjPCZ"
   },
   "source": [
    "#### Training and evaluation\n",
    "\n",
    "As usual, we gonna feed our monster with random minibatches of data. \n",
    "\n",
    "As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vO3BzT6mjPCZ"
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(data, batch_size=256, shuffle=True, cycle=False, **kwargs):\n",
    "    \"\"\" iterates minibatches of data in random order \"\"\"\n",
    "    while True:\n",
    "        indices = np.arange(len(data))\n",
    "        if shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start in range(0, len(indices), batch_size):\n",
    "            batch = make_batch(data.iloc[indices[start : start + batch_size]], **kwargs)\n",
    "            target = batch.pop(target_column)\n",
    "            yield batch, target\n",
    "        \n",
    "        if not cycle: break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U9ex0EeljPCd"
   },
   "source": [
    "### Model training\n",
    "\n",
    "We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by `iterate_minibatches` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 749
    },
    "colab_type": "code",
    "id": "Ge6o3ETujPCd",
    "outputId": "6acb49fe-2046-45cf-e461-b9922eb814c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 12.3473 - mean_absolute_error: 2.0772Epoch 1/10\n",
      "191/100 [=========================================================] - 38s 199ms/step - loss: 0.2775 - mean_absolute_error: 0.4099\n",
      "100/100 [==============================] - 113s 1s/step - loss: 12.2266 - mean_absolute_error: 2.0605 - val_loss: 0.2778 - val_mean_absolute_error: 0.4099\n",
      "Epoch 2/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.2111 - mean_absolute_error: 0.3567Epoch 1/10\n",
      "191/100 [=========================================================] - 38s 201ms/step - loss: 0.1643 - mean_absolute_error: 0.3144\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2110 - mean_absolute_error: 0.3566 - val_loss: 0.1674 - val_mean_absolute_error: 0.3144\n",
      "Epoch 3/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1504 - mean_absolute_error: 0.2975Epoch 1/10\n",
      "191/100 [=========================================================] - 39s 203ms/step - loss: 0.1303 - mean_absolute_error: 0.2779\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.1501 - mean_absolute_error: 0.2971 - val_loss: 0.1322 - val_mean_absolute_error: 0.2779\n",
      "Epoch 4/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1241 - mean_absolute_error: 0.2692Epoch 1/10\n",
      "191/100 [=========================================================] - 39s 205ms/step - loss: 0.1202 - mean_absolute_error: 0.2602\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.1242 - mean_absolute_error: 0.2694 - val_loss: 0.1179 - val_mean_absolute_error: 0.2602\n",
      "Epoch 5/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1156 - mean_absolute_error: 0.2574Epoch 1/10\n",
      "191/100 [=========================================================] - 39s 202ms/step - loss: 0.1087 - mean_absolute_error: 0.2467\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.1153 - mean_absolute_error: 0.2570 - val_loss: 0.1067 - val_mean_absolute_error: 0.2467\n",
      "Epoch 6/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1056 - mean_absolute_error: 0.2460Epoch 1/10\n",
      "191/100 [=========================================================] - 39s 202ms/step - loss: 0.0973 - mean_absolute_error: 0.2379\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.1056 - mean_absolute_error: 0.2461 - val_loss: 0.0999 - val_mean_absolute_error: 0.2379\n",
      "Epoch 7/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.1014 - mean_absolute_error: 0.2389Epoch 1/10\n",
      "191/100 [=========================================================] - 38s 197ms/step - loss: 0.0903 - mean_absolute_error: 0.2306\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.1015 - mean_absolute_error: 0.2388 - val_loss: 0.0940 - val_mean_absolute_error: 0.2306\n",
      "Epoch 8/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0931 - mean_absolute_error: 0.2284Epoch 1/10\n",
      "191/100 [=========================================================] - 38s 198ms/step - loss: 0.0871 - mean_absolute_error: 0.2248\n",
      "100/100 [==============================] - 110s 1s/step - loss: 0.0929 - mean_absolute_error: 0.2282 - val_loss: 0.0894 - val_mean_absolute_error: 0.2248\n",
      "Epoch 9/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0842 - mean_absolute_error: 0.2172Epoch 1/10\n",
      "191/100 [=========================================================] - 39s 206ms/step - loss: 0.0842 - mean_absolute_error: 0.2229\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.0842 - mean_absolute_error: 0.2173 - val_loss: 0.0885 - val_mean_absolute_error: 0.2229\n",
      "Epoch 10/10\n",
      " 99/100 [============================>.] - ETA: 0s - loss: 0.0798 - mean_absolute_error: 0.2117Epoch 1/10\n",
      "191/100 [=========================================================] - 39s 207ms/step - loss: 0.0853 - mean_absolute_error: 0.2192\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.0799 - mean_absolute_error: 0.2118 - val_loss: 0.0860 - val_mean_absolute_error: 0.2192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6cfe09d198>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 10            # definitely too small\n",
    "steps_per_epoch = 100  # for full pass over data: (len(data_train) - 1) // batch_size + 1\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.fit_generator(iterate_minibatches(data_train, batch_size, cycle=True, word_dropout=0.05), \n",
    "                    epochs=epochs, steps_per_epoch=steps_per_epoch,\n",
    "                    \n",
    "                    validation_data=iterate_minibatches(data_val, batch_size, cycle=True),\n",
    "                    validation_steps=data_val.shape[0] // batch_size\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "sUoOqspcjPCh",
    "outputId": "28af8a85-0600-42c9-c01a-4f983e314424"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train results:\n",
      "Mean square error: 0.07419\n",
      "Mean absolute error: 0.20220\n",
      "Val results:\n",
      "Mean square error: 0.08560\n",
      "Mean absolute error: 0.21897\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(model, data, batch_size=batch_size, name=\"\", **kw):\n",
    "    squared_error = abs_error = num_samples = 0.0\n",
    "    for batch_x, batch_y in iterate_minibatches(data, batch_size=batch_size, shuffle=False, **kw):\n",
    "        batch_pred = model.predict(batch_x)[:, 0]\n",
    "        squared_error += np.sum(np.square(batch_pred - batch_y))\n",
    "        abs_error += np.sum(np.abs(batch_pred - batch_y))\n",
    "        num_samples += len(batch_y)\n",
    "    print(\"%s results:\" % (name or \"\"))\n",
    "    print(\"Mean square error: %.5f\" % (squared_error / num_samples))\n",
    "    print(\"Mean absolute error: %.5f\" % (abs_error / num_samples))\n",
    "    return squared_error, abs_error\n",
    "    \n",
    "print_metrics(model, data_train, name='Train')\n",
    "print_metrics(model, data_val, name='Val');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xIZ85cYkjPCk"
   },
   "source": [
    "### Bonus part: explaining model predictions\n",
    "\n",
    "It's usually a good idea to understand how your model works before you let it make actual decisions. It's simple for linear models: just see which words learned positive or negative weights. However, its much harder for neural networks that learn complex nonlinear dependencies.\n",
    "\n",
    "There are, however, some ways to look inside the black box:\n",
    "* Seeing how model responds to input perturbations\n",
    "* Finding inputs that maximize/minimize activation of some chosen neurons (_read more [on distill.pub](https://distill.pub/2018/building-blocks/)_)\n",
    "* Building local linear approximations to your neural network: [article](https://arxiv.org/abs/1602.04938), [eli5 library](https://github.com/TeamHG-Memex/eli5/tree/master/eli5/formatters)\n",
    "\n",
    "Today we gonna try the first method just because it's the simplest one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hENsUdJbjPCl"
   },
   "outputs": [],
   "source": [
    "def explain(model, sample, col_name='Title'):\n",
    "    \"\"\" Computes the effect each word had on model predictions \"\"\"\n",
    "    sample = dict(sample)\n",
    "    sample_col_tokens = [tokens[token_to_id.get(tok, 0)] for tok in sample[col_name].split()]\n",
    "    data_drop_one_token = pd.DataFrame([sample] * (len(sample_col_tokens) + 1))\n",
    "\n",
    "    for drop_i in range(len(sample_col_tokens)):\n",
    "        data_drop_one_token.loc[drop_i, col_name] = ' '.join(UNK if i == drop_i else tok\n",
    "                                                   for i, tok in enumerate(sample_col_tokens)) \n",
    "\n",
    "    *predictions_drop_one_token, baseline_pred = model.predict(make_batch(data_drop_one_token))[:, 0]\n",
    "    diffs = baseline_pred - predictions_drop_one_token\n",
    "    return list(zip(sample_col_tokens, diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pFuROJ5vjPCn"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display_html\n",
    "\n",
    "def draw_html(tokens_and_weights, cmap=plt.get_cmap(\"bwr\"), display=True,\n",
    "              token_template=\"\"\"<span style=\"background-color: {color_hex}\">{token}</span>\"\"\",\n",
    "              font_style=\"font-size:14px;\"\n",
    "             ):\n",
    "    \n",
    "    def get_color_hex(weight):\n",
    "        rgba = cmap(1. / (1 + np.exp(weight)), bytes=True)\n",
    "        return '#%02X%02X%02X' % rgba[:3]\n",
    "    \n",
    "    tokens_html = [\n",
    "        token_template.format(token=token, color_hex=get_color_hex(weight))\n",
    "        for token, weight in tokens_and_weights\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    raw_html = \"\"\"<p style=\"{}\">{}</p>\"\"\".format(font_style, ' '.join(tokens_html))\n",
    "    if display:\n",
    "        display_html(HTML(raw_html))\n",
    "        \n",
    "    return raw_html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "colab_type": "code",
    "id": "hmhqtRKhjPCp",
    "outputId": "8189661c-7e1e-47c3-d755-8b455ab967c4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #EAEAFF\">sales</span> <span style=\"background-color: #9696FF\">specialist</span> <span style=\"background-color: #BEBEFF\">iv</span> <span style=\"background-color: #9696FF\">access</span> <span style=\"background-color: #C6C6FF\">and</span> <span style=\"background-color: #F2F2FF\">infusion</span></p>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px;\"><span style=\"background-color: #FEFEFF\">sales</span> <span style=\"background-color: #FEFEFF\">representative</span> <span style=\"background-color: #FEFEFF\">medical</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #F2F2FF\">an</span> <span style=\"background-color: #F2F2FF\">opportunity</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">work</span> <span style=\"background-color: #FFFEFE\">for</span> <span style=\"background-color: #FFF0F0\">the</span> <span style=\"background-color: #FFF0F0\">industry</span> <span style=\"background-color: #FFFEFE\">leading</span> <span style=\"background-color: #F8F8FF\">manufacturer</span> <span style=\"background-color: #F3F3FF\">of</span> <span style=\"background-color: #F3F3FF\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFAFA\">.</span> <span style=\"background-color: #FFFEFE\">formally</span> <span style=\"background-color: #FFFEFE\">recognised</span> <span style=\"background-color: #FFFEFE\">as</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFFAFA\">number</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">company</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FAFAFF\">market</span> <span style=\"background-color: #FFFAFA\">space</span> <span style=\"background-color: #FAFAFF\">,</span> <span style=\"background-color: #FFFEFE\">our</span> <span style=\"background-color: #FFFEFE\">client</span> <span style=\"background-color: #FFFCFC\">are</span> <span style=\"background-color: #FFFEFE\">an</span> <span style=\"background-color: #FFFEFE\">ethical</span> <span style=\"background-color: #FFF4F4\">and</span> <span style=\"background-color: #FFFEFE\">dynamic</span> <span style=\"background-color: #FFFEFE\">organisation</span> <span style=\"background-color: #FFFEFE\">absolutely</span> <span style=\"background-color: #FFFEFE\">committed</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #F8F8FF\">the</span> <span style=\"background-color: #FAFAFF\">advancement</span> <span style=\"background-color: #F8F8FF\">of</span> <span style=\"background-color: #FFFCFC\">innovative</span> <span style=\"background-color: #FFF4F4\">technologies</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">job</span> <span style=\"background-color: #FFFEFE\">title</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">selling</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">medication</span> <span style=\"background-color: #FFFEFE\">delivery</span> <span style=\"background-color: #FAFAFF\">solutions</span> <span style=\"background-color: #FFF8F8\">selling</span> <span style=\"background-color: #FAFAFF\">to</span> <span style=\"background-color: #FEFEFF\">:</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FEFEFF\">teams</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">infection</span> <span style=\"background-color: #F2F2FF\">control</span> <span style=\"background-color: #F2F2FF\">,</span> <span style=\"background-color: #F3F3FF\">lead</span> <span style=\"background-color: #FFFEFE\">intensive</span> <span style=\"background-color: #FFEEEE\">care</span> <span style=\"background-color: #FFFEFE\">nurse</span> <span style=\"background-color: #FFFEFE\">specialists</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">ward</span> <span style=\"background-color: #F3F3FF\">managers</span> <span style=\"background-color: #F3F3FF\">territory</span> <span style=\"background-color: #F3F3FF\">:</span> <span style=\"background-color: #FAFAFF\">east</span> <span style=\"background-color: #ECECFF\">midlands</span> <span style=\"background-color: #ECECFF\">location</span> <span style=\"background-color: #F6F6FF\">:</span> <span style=\"background-color: #FFFAFA\">east</span> <span style=\"background-color: #FFFEFE\">midlands</span> <span style=\"background-color: #FFFEFE\">package</span> <span style=\"background-color: #FFF6F6\">:</span> <span style=\"background-color: #FFFEFE\">basic</span> <span style=\"background-color: #FFFEFE\">:</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">k</span> <span style=\"background-color: #FFFCFC\">****</span> <span style=\"background-color: #FFF4F4\">k</span> <span style=\"background-color: #F8F8FF\">,</span> <span style=\"background-color: #FCFCFF\">uncapped</span> <span style=\"background-color: #FAFAFF\">bonus</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">addition</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">full</span> <span style=\"background-color: #F0F0FF\">corporate</span> <span style=\"background-color: #FCFCFF\">benefits</span> <span style=\"background-color: #F6F6FF\">company</span> <span style=\"background-color: #FFFEFE\">information</span> <span style=\"background-color: #FFFEFE\">hugely</span> <span style=\"background-color: #FFD2D2\">ethical</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">professional</span> <span style=\"background-color: #FAFAFF\">global</span> <span style=\"background-color: #FFFCFC\">organisation</span> <span style=\"background-color: #FFFCFC\">extremely</span> <span style=\"background-color: #FFFEFE\">well</span> <span style=\"background-color: #FFFEFE\">established</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FCFCFF\">uk</span> <span style=\"background-color: #FCFCFF\">the</span> <span style=\"background-color: #FFFEFE\">market</span> <span style=\"background-color: #FFFCFC\">leader</span> <span style=\"background-color: #FFFEFE\">across</span> <span style=\"background-color: #FFFEFE\">all</span> <span style=\"background-color: #FFF0F0\">of</span> <span style=\"background-color: #FFF4F4\">their</span> <span style=\"background-color: #FFFEFE\">core</span> <span style=\"background-color: #FFFEFE\">business</span> <span style=\"background-color: #FFEAEA\">areas</span> <span style=\"background-color: #F3F3FF\">focus</span> <span style=\"background-color: #EEEEFF\">on</span> <span style=\"background-color: #FCFCFF\">providing</span> <span style=\"background-color: #F2F2FF\">cutting</span> <span style=\"background-color: #EEEEFF\">edge</span> <span style=\"background-color: #FEFEFF\">solutions</span> <span style=\"background-color: #FFECEC\">along</span> <span style=\"background-color: #FFFEFE\">with</span> <span style=\"background-color: #FFFEFE\">outstanding</span> <span style=\"background-color: #FFFEFE\">service</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">support</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">business</span> <span style=\"background-color: #FFFEFE\">that</span> <span style=\"background-color: #FFFEFE\">retain</span> <span style=\"background-color: #FFFEFE\">talented</span> <span style=\"background-color: #FFFEFE\">personnel</span> <span style=\"background-color: #FFFEFE\">by</span> <span style=\"background-color: #FFFEFE\">offering</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFF6F6\">strong</span> <span style=\"background-color: #FFFAFA\">platform</span> <span style=\"background-color: #FEFEFF\">for</span> <span style=\"background-color: #FFFAFA\">career</span> <span style=\"background-color: #FFFEFE\">development</span> <span style=\"background-color: #FFFEFE\">sales</span> <span style=\"background-color: #FFFEFE\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFEEEE\">you</span> <span style=\"background-color: #FCFCFF\">must</span> <span style=\"background-color: #FCFCFF\">have</span> <span style=\"background-color: #FEFEFF\">/</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFEAEA\">following</span> <span style=\"background-color: #FFFEFE\">at</span> <span style=\"background-color: #FFFEFE\">least</span> <span style=\"background-color: #FFF2F2\">2</span> <span style=\"background-color: #F8F8FF\">years</span> <span style=\"background-color: #ECECFF\">medical</span> <span style=\"background-color: #ECECFF\">device</span> <span style=\"background-color: #FFF8F8\">sales</span> <span style=\"background-color: #FFFCFC\">experience</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFE0E0\">candidates</span> <span style=\"background-color: #FFFEFE\">who</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #F8F8FF\">sold</span> <span style=\"background-color: #F8F8FF\">disposables</span> <span style=\"background-color: #F8F8FF\">/</span> <span style=\"background-color: #FFFEFE\">consumables</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #F3F3FF\">similar</span> <span style=\"background-color: #FFFEFE\">into</span> <span style=\"background-color: #F3F3FF\">hospitals</span> <span style=\"background-color: #FFF6F6\">would</span> <span style=\"background-color: #FFFAFA\">be</span> <span style=\"background-color: #FEFEFF\">of</span> <span style=\"background-color: #FFFEFE\">particular</span> <span style=\"background-color: #FFFCFC\">interest</span> <span style=\"background-color: #FFECEC\">.</span> <span style=\"background-color: #FFEEEE\">candidates</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">sold</span> <span style=\"background-color: #FFFAFA\">into</span> <span style=\"background-color: #FAFAFF\">hospitals</span> <span style=\"background-color: #FFFAFA\">demonstrable</span> <span style=\"background-color: #F8F8FF\">performance</span> <span style=\"background-color: #F8F8FF\">and</span> <span style=\"background-color: #F8F8FF\">achievements</span> <span style=\"background-color: #FFFEFE\">so</span> <span style=\"background-color: #FFFEFE\">far</span> <span style=\"background-color: #FFFEFE\">personable</span> <span style=\"background-color: #FEFEFF\">,</span> <span style=\"background-color: #FFFEFE\">adaptable</span> <span style=\"background-color: #FEFEFF\">and</span> <span style=\"background-color: #FFFEFE\">willing</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">learn</span> <span style=\"background-color: #FFFEFE\">keen</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">eager</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFDADA\">success</span> <span style=\"background-color: #FFEEEE\">candidates</span> <span style=\"background-color: #FFFEFE\">must</span> <span style=\"background-color: #FFFEFE\">have</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">degree</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #FFFEFE\">at</span> <span style=\"background-color: #FFFEFE\">least</span> <span style=\"background-color: #FFFEFE\">be</span> <span style=\"background-color: #FFFEFE\">able</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">show</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #F6F6FF\">strong</span> <span style=\"background-color: #FFFAFA\">ability</span> <span style=\"background-color: #FEFEFF\">to</span> <span style=\"background-color: #FFFEFE\">learn</span> <span style=\"background-color: #FFFEFE\">role</span> <span style=\"background-color: #FFFCFC\">information</span> <span style=\"background-color: #FFFEFE\">managing</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #FFF4F4\">east</span> <span style=\"background-color: #FEFEFF\">midlands</span> <span style=\"background-color: #E8E8FF\">region</span> <span style=\"background-color: #FFF2F2\">selling</span> <span style=\"background-color: #E6E6FF\">across</span> <span style=\"background-color: #FCFCFF\">the</span> <span style=\"background-color: #FEFEFF\">company</span> <span style=\"background-color: #FEFEFF\">'</span> <span style=\"background-color: #FEFEFF\">s</span> <span style=\"background-color: #FEFEFF\">range</span> <span style=\"background-color: #FEFEFF\">of</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">infusion</span> <span style=\"background-color: #FFFEFE\">solutions</span> <span style=\"background-color: #FFFEFE\">portfolio</span> <span style=\"background-color: #FFF8F8\">selling</span> <span style=\"background-color: #FEFEFF\">into</span> <span style=\"background-color: #FFFEFE\">lead</span> <span style=\"background-color: #FFFCFC\">intensive</span> <span style=\"background-color: #FFEEEE\">care</span> <span style=\"background-color: #FFFEFE\">nurse</span> <span style=\"background-color: #FFFEFE\">specialists</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">ward</span> <span style=\"background-color: #FFFEFE\">managers</span> <span style=\"background-color: #FFF6F6\">,</span> <span style=\"background-color: #FAFAFF\">iv</span> <span style=\"background-color: #FAFAFF\">teams</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFFEFE\">infection</span> <span style=\"background-color: #FFFEFE\">control</span> <span style=\"background-color: #FEFEFF\">teams</span> <span style=\"background-color: #FFF0F0\">,</span> <span style=\"background-color: #FCFCFF\">procurement</span> <span style=\"background-color: #FCFCFF\">sales</span> <span style=\"background-color: #FCFCFF\">specialist</span> <span style=\"background-color: #FFFEFE\">iv</span> <span style=\"background-color: #FFFEFE\">access</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFEEEE\">infusion</span> <span style=\"background-color: #FEFEFF\">candidates</span> <span style=\"background-color: #FCFCFF\">must</span> <span style=\"background-color: #FEFEFF\">be</span> <span style=\"background-color: #FFFEFE\">eligible</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">work</span> <span style=\"background-color: #FFFEFE\">and</span> <span style=\"background-color: #FFFEFE\">live</span> <span style=\"background-color: #FFFEFE\">in</span> <span style=\"background-color: #FFFCFC\">the</span> <span style=\"background-color: #FFFEFE\">uk</span> <span style=\"background-color: #F3F3FF\">.</span> <span style=\"background-color: #F3F3FF\">please</span> <span style=\"background-color: #F3F3FF\">contact</span> <span style=\"background-color: #FFF0F0\">allan</span> <span style=\"background-color: #FFFEFE\">waller</span> <span style=\"background-color: #FFFEFE\">on</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFFEFE\">****</span> <span style=\"background-color: #FFDEDE\">****</span> <span style=\"background-color: #FFDEDE\">or</span> <span style=\"background-color: #FCFCFF\">please</span> <span style=\"background-color: #F0F0FF\">hit</span> <span style=\"background-color: #FFFAFA\">the</span> <span style=\"background-color: #F3F3FF\">apply</span> <span style=\"background-color: #FFFEFE\">button</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">this</span> <span style=\"background-color: #FFFEFE\">job</span> <span style=\"background-color: #FEFEFF\">was</span> <span style=\"background-color: #FFF8F8\">originally</span> <span style=\"background-color: #FEFEFF\">posted</span> <span style=\"background-color: #FCFCFF\">as</span> <span style=\"background-color: #FCFCFF\">www</span> <span style=\"background-color: #FAFAFF\">.</span> <span style=\"background-color: #FCFCFF\">salestarget</span> <span style=\"background-color: #FCFCFF\">.</span> <span style=\"background-color: #FFFEFE\">co</span> <span style=\"background-color: #FFF4F4\">.</span> <span style=\"background-color: #F8F8FF\">uk</span> <span style=\"background-color: #F2F2FF\">/</span> <span style=\"background-color: #EEEEFF\">jobseeking</span> <span style=\"background-color: #EAEAFF\">/</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFFEFE\">****</span></p>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 36605\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 95
    },
    "colab_type": "code",
    "id": "99ElI6izjPCs",
    "outputId": "45bb3727-a39e-4cce-935b-f53cefdd1ecf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #FFFEFE\">cleaning</span> <span style=\"background-color: #FFFEFE\">operative</span></p>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px;\"><span style=\"background-color: #FFFEFE\">12</span> <span style=\"background-color: #FFE6E6\">.</span> <span style=\"background-color: #FFFEFE\">5</span> <span style=\"background-color: #FFD3D3\">hours</span> <span style=\"background-color: #FFF8F8\">per</span> <span style=\"background-color: #F0F0FF\">week</span> <span style=\"background-color: #FCFCFF\">monday</span> <span style=\"background-color: #FFF4F4\">friday</span> <span style=\"background-color: #F8F8FF\">9am</span> <span style=\"background-color: #FEFEFF\">11</span> <span style=\"background-color: #FFF4F4\">.</span> <span style=\"background-color: #FFDCDC\">30am</span> <span style=\"background-color: #FFDEDE\">duties</span> <span style=\"background-color: #EAEAFF\">to</span> <span style=\"background-color: #C8C8FF\">include</span> <span style=\"background-color: #FCFCFF\">sweeping</span> <span style=\"background-color: #DCDCFF\">,</span> <span style=\"background-color: #E6E6FF\">mopping</span> <span style=\"background-color: #D8D8FF\">,</span> <span style=\"background-color: #F8F8FF\">vacuuming</span> <span style=\"background-color: #FFF4F4\">,</span> <span style=\"background-color: #F8F8FF\">buffing</span> <span style=\"background-color: #FFFEFE\">,</span> <span style=\"background-color: #FFE2E2\">cleaning</span> <span style=\"background-color: #FFF6F6\">staff</span> <span style=\"background-color: #FFE4E4\">toilets</span> <span style=\"background-color: #F2F2FF\">and</span> <span style=\"background-color: #E0E0FF\">rest</span> <span style=\"background-color: #FFEAEA\">room</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFCFC\">must</span> <span style=\"background-color: #FFC6C6\">be</span> <span style=\"background-color: #FFECEC\">able</span> <span style=\"background-color: #FFF0F0\">to</span> <span style=\"background-color: #FEFEFF\">read</span> <span style=\"background-color: #FFF8F8\">as</span> <span style=\"background-color: #FFDEDE\">they</span> <span style=\"background-color: #FFF6F6\">will</span> <span style=\"background-color: #FCFCFF\">be</span> <span style=\"background-color: #FFEEEE\">using</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFFAFA\">which</span> <span style=\"background-color: #FFEEEE\">need</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #FFECEC\">as</span> <span style=\"background-color: #FFF0F0\">per</span> <span style=\"background-color: #FFFEFE\">instructions</span> <span style=\"background-color: #FAFAFF\">on</span> <span style=\"background-color: #F8F8FF\">the</span> <span style=\"background-color: #FFE6E6\">containers</span> <span style=\"background-color: #FFF2F2\">.</span> <span style=\"background-color: #E0E0FF\">sucessfull</span> <span style=\"background-color: #C3C3FF\">applicants</span> <span style=\"background-color: #B2B2FF\">will</span> <span style=\"background-color: #FFECEC\">be</span> <span style=\"background-color: #FFFAFA\">trained</span> <span style=\"background-color: #FFF8F8\">on</span> <span style=\"background-color: #FAFAFF\">all</span> <span style=\"background-color: #FFF0F0\">electrical</span> <span style=\"background-color: #FFFEFE\">appliances</span> <span style=\"background-color: #FFC8C8\">and</span> <span style=\"background-color: #FFFEFE\">UNK</span> <span style=\"background-color: #E8E8FF\">of</span> <span style=\"background-color: #EEEEFF\">cleaning</span> <span style=\"background-color: #F8F8FF\">materials</span> <span style=\"background-color: #E8E8FF\">.</span></p>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 12077\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "rys_Q8S_jPCv",
    "outputId": "1242b53a-d7b8-4761-d74e-da23cf019a3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 97496\n",
      "Salary (gbp): 7357.169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:20px;\"><span style=\"background-color: #F8F8FF\">vbnet</span> <span style=\"background-color: #4848FF\">developer</span> <span style=\"background-color: #BCBCFF\">exeter</span> <span style=\"background-color: #FFEEEE\">****</span></p>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p style=\"font-size:14px;\"><span style=\"background-color: #DEDEFF\">i</span> <span style=\"background-color: #E2E2FF\">am</span> <span style=\"background-color: #DCDCFF\">currently</span> <span style=\"background-color: #FFF8F8\">looking</span> <span style=\"background-color: #F6F6FF\">for</span> <span style=\"background-color: #EEEEFF\">a</span> <span style=\"background-color: #FFFCFC\">senior</span> <span style=\"background-color: #DADAFF\">developer</span> <span style=\"background-color: #F8F8FF\">to</span> <span style=\"background-color: #E6E6FF\">join</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFEAEA\">growing</span> <span style=\"background-color: #FFFEFE\">team</span> <span style=\"background-color: #FFFEFE\">dedicated</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #F0F0FF\">the</span> <span style=\"background-color: #FFFEFE\">delivery</span> <span style=\"background-color: #E3E3FF\">of</span> <span style=\"background-color: #F8F8FF\">modern</span> <span style=\"background-color: #F6F6FF\">technologies</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">service</span> <span style=\"background-color: #F3F3FF\">the</span> <span style=\"background-color: #F2F2FF\">client</span> <span style=\"background-color: #FFFEFE\">’</span> <span style=\"background-color: #FFFEFE\">s</span> <span style=\"background-color: #FFFEFE\">current</span> <span style=\"background-color: #FFFAFA\">and</span> <span style=\"background-color: #FFE2E2\">future</span> <span style=\"background-color: #F8F8FF\">growth</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">the</span> <span style=\"background-color: #DADAFF\">role</span> <span style=\"background-color: #D0D0FF\">will</span> <span style=\"background-color: #D6D6FF\">involve</span> <span style=\"background-color: #F8F8FF\">design</span> <span style=\"background-color: #F6F6FF\">,</span> <span style=\"background-color: #F2F2FF\">development</span> <span style=\"background-color: #FFFCFC\">and</span> <span style=\"background-color: #F8F8FF\">implementation</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">applications</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">you</span> <span style=\"background-color: #FFFEFE\">will</span> <span style=\"background-color: #FFF8F8\">need</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFFEFE\">minimum</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFE2E2\">2</span> <span style=\"background-color: #FFF2F2\">years</span> <span style=\"background-color: #FFE8E8\">development</span> <span style=\"background-color: #ECECFF\">experience</span> <span style=\"background-color: #FFE8E8\">and</span> <span style=\"background-color: #FFF8F8\">have</span> <span style=\"background-color: #FFFAFA\">strong</span> <span style=\"background-color: #FFFAFA\">vb</span> <span style=\"background-color: #F8F8FF\">.</span> <span style=\"background-color: #FCFCFF\">net</span> <span style=\"background-color: #FFECEC\">web</span> <span style=\"background-color: #FFFEFE\">development</span> <span style=\"background-color: #FFFEFE\">skills</span> <span style=\"background-color: #FFFCFC\">.</span> <span style=\"background-color: #FFFCFC\">vb</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">net</span> <span style=\"background-color: #FFEEEE\">/</span> <span style=\"background-color: #FFFEFE\">/</span> <span style=\"background-color: #FEFEFF\">asp</span> <span style=\"background-color: #FEFEFF\">.</span> <span style=\"background-color: #FFFCFC\">net</span> <span style=\"background-color: #FEFEFF\">/</span> <span style=\"background-color: #F2F2FF\">mvc</span> <span style=\"background-color: #E0E0FF\">/</span> <span style=\"background-color: #EEEEFF\">sql</span> <span style=\"background-color: #F6F6FF\">server</span> <span style=\"background-color: #FFE4E4\">if</span> <span style=\"background-color: #F8F8FF\">this</span> <span style=\"background-color: #F3F3FF\">is</span> <span style=\"background-color: #E8E8FF\">an</span> <span style=\"background-color: #E8E8FF\">opportunity</span> <span style=\"background-color: #FFF0F0\">you</span> <span style=\"background-color: #FFFEFE\">would</span> <span style=\"background-color: #FFFEFE\">like</span> <span style=\"background-color: #FFFAFA\">to</span> <span style=\"background-color: #FCFCFF\">be</span> <span style=\"background-color: #FFFEFE\">put</span> <span style=\"background-color: #FAFAFF\">forward</span> <span style=\"background-color: #FFE8E8\">for</span> <span style=\"background-color: #FFF6F6\">,</span> <span style=\"background-color: #FFFEFE\">then</span> <span style=\"background-color: #C8C8FF\">please</span> <span style=\"background-color: #C3C3FF\">send</span> <span style=\"background-color: #FFFCFC\">me</span> <span style=\"background-color: #FFFEFE\">a</span> <span style=\"background-color: #FFEAEA\">copy</span> <span style=\"background-color: #FFFEFE\">of</span> <span style=\"background-color: #FFFEFE\">your</span> <span style=\"background-color: #FFFEFE\">updated</span> <span style=\"background-color: #FFFEFE\">cv</span> <span style=\"background-color: #FFFEFE\">or</span> <span style=\"background-color: #FFFEFE\">give</span> <span style=\"background-color: #F8F8FF\">me</span> <span style=\"background-color: #F2F2FF\">a</span> <span style=\"background-color: #FFF2F2\">call</span> <span style=\"background-color: #F8F8FF\">on</span> <span style=\"background-color: #DCDCFF\">[</span> <span style=\"background-color: #CCCCFF\">blocked</span> <span style=\"background-color: #CCCCFF\">]</span> <span style=\"background-color: #D8D8FF\">l</span> <span style=\"background-color: #F0F0FF\">.</span> <span style=\"background-color: #DEDEFF\">i</span> <span style=\"background-color: #FFF6F6\">look</span> <span style=\"background-color: #FFFEFE\">forward</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FFFEFE\">hearing</span> <span style=\"background-color: #FFFAFA\">from</span> <span style=\"background-color: #FFFAFA\">you</span> <span style=\"background-color: #FFFEFE\">.</span> <span style=\"background-color: #FFFEFE\">to</span> <span style=\"background-color: #FCFCFF\">find</span> <span style=\"background-color: #E3E3FF\">out</span> <span style=\"background-color: #ECECFF\">more</span> <span style=\"background-color: #F2F2FF\">about</span> <span style=\"background-color: #FFFEFE\">computer</span> <span style=\"background-color: #A2A2FF\">futures</span> <span style=\"background-color: #D6D6FF\">please</span> <span style=\"background-color: #DCDCFF\">visit</span> <span style=\"background-color: #FFFAFA\">www</span> <span style=\"background-color: #D0D0FF\">.</span> <span style=\"background-color: #ACACFF\">computerfutures</span> <span style=\"background-color: #C8C8FF\">.</span> <span style=\"background-color: #FFE8E8\">com</span></p>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(len(data))\n",
    "print(\"Index:\", i)\n",
    "print(\"Salary (gbp):\", np.expm1(model.predict(make_batch(data.iloc[i: i+1]))[0, 0]))\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"Title\")\n",
    "draw_html([(tok, weight * 5) for tok, weight in tokens_and_weights], font_style='font-size:20px;');\n",
    "\n",
    "tokens_and_weights = explain(model, data.loc[i], \"FullDescription\")\n",
    "draw_html([(tok, weight * 10) for tok, weight in tokens_and_weights]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DqgqYRsQjPCy"
   },
   "source": [
    "__Terrible start-up idea #1962:__ make a tool that automaticaly rephrases your job description (or CV) to meet salary expectations :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIwDfmrYOMfi"
   },
   "source": [
    "### Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6DaLniC6MhY"
   },
   "source": [
    "#### 20 newsgroups\n",
    "Датасет с 18000 новостей, сгруппированных по 20 темам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uS7IJNW6Mhb",
    "outputId": "ebc2f876-92c7-4032-a422-d51b2e3c2c4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MMbagpJE6Mhh",
    "outputId": "152aa470-abef-47d0-deb1-2bcef6280e07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7QReW1K46Mhn",
    "outputId": "d243da37-1e2a-4a19-e22b-960f369915c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314,)"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WZtRIQmNQ4H0"
   },
   "source": [
    "#### Рассмотрим подвыборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OhwuCp5B6Mhz",
    "outputId": "53f9bb20-9762-49b3-f2f2-0327bde7d576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034,)"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "newsgroups_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MOREsv336MiA",
    "outputId": "f91d5c50-4e47-4ba9-cbbe-37acf3df847a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: rych@festival.ed.ac.uk (R Hawkes)\n",
      "Subject: 3DS: Where did all the texture rules go?\n",
      "Lines: 21\n",
      "\n",
      "Hi,\n",
      "\n",
      "I've noticed that if you only save a model (with all your mapping planes\n",
      "positioned carefully) to a .3DS file that when you reload it after restarting\n",
      "3DS, they are given a default position and orientation.  But if you save\n",
      "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
      "know why this information is not stored in the .3DS file?  Nothing is\n",
      "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
      "I'd like to be able to read the texture rule information, does anyone have \n",
      "the format for the .PRJ file?\n",
      "\n",
      "Is the .CEL file format available from somewhere?\n",
      "\n",
      "Rych\n",
      "\n",
      "======================================================================\n",
      "Rycharde Hawkes\t\t\t\temail: rych@festival.ed.ac.uk\n",
      "Virtual Environment Laboratory\n",
      "Dept. of Psychology\t\t\tTel  : +44 31 650 3426\n",
      "Univ. of Edinburgh\t\t\tFax  : +44 31 667 0150\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroups_train.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBnDG-TN6MiF",
    "outputId": "33bc189f-0161-4287-bf48-e78fcdadd683"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0, 2, 0, 2, 1, 2, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_train.target[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XlZYpodRYDI"
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohUk2n3jRbNp"
   },
   "source": [
    "$n_{\\mathbb{d}\\mathbb{w}}$ - число вхождений слова $\\mathbb{w}$ в документ $\\mathbb{d}$;<br>\n",
    "$N_{\\mathbb{w}}$ - число документов, содержащих $\\mathbb{w}$;<br>\n",
    "$N$ - число документов; <br><br>\n",
    "\n",
    "$p(\\mathbb{w}, \\mathbb{d}) = N_{\\mathbb{w}} / N$ - вероятность наличия слова $\\mathbb{w}$ в любом документе $\\mathbb{d}$\n",
    "<br>\n",
    "$P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}}) = (N_{\\mathbb{w}} / N)^{n_{\\mathbb{d}\\mathbb{w}}}$ - вероятность встретить $n_{\\mathbb{d}\\mathbb{w}}$ раз слово $\\mathbb{w}$ в документе $\\mathbb{d}$<br><br>\n",
    "\n",
    "$-\\log{P(\\mathbb{w}, \\mathbb{d}, n_{\\mathbb{d}\\mathbb{w}})} = n_{\\mathbb{d}\\mathbb{w}} \\cdot \\log{(N / N_{\\mathbb{w}})} = TF(\\mathbb{w}, \\mathbb{d}) \\cdot IDF(\\mathbb{w})$<br><br>\n",
    "\n",
    "$TF(\\mathbb{w}, \\mathbb{d}) = n_{\\mathbb{d}\\mathbb{w}}$ - term frequency;<br>\n",
    "$IDF(\\mathbb{w}) = \\log{(N /N_{\\mathbb{w}})}$ - inverted document frequency;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQvcMiFH6MiM"
   },
   "source": [
    "#### Давайте векторизуем эти тексты с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "98LLAoZO6MiU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baXLU0lj6MiY"
   },
   "source": [
    "#### Некоторые параметры: \n",
    "* input : string {‘filename’, ‘file’, ‘content’}\n",
    "*  lowercase : boolean, default True\n",
    "*  preprocessor : callable or None (default)\n",
    "*  tokenizer : callable or None (default)\n",
    "*  stop_words : string {‘english’}, list, or None (default)\n",
    "*  ngram_range : tuple (min_n, max_n)\n",
    "*  max_df : float in range [0.0, 1.0] or int, default=1.0\n",
    "*  min_df : float in range [0.0, 1.0] or int, default=1\n",
    "*  max_features : int or None, default=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O-m81BJxZFwJ"
   },
   "source": [
    "#### Перебор параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_f7padHL6MiZ",
    "outputId": "a60445fa-ad78-4efb-ad13-51a8a59f5650"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 34118)"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercase\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nf2s4HCY6Mie",
    "outputId": "159178a7-2cb6-438f-93fd-2532ec410368"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 42307)"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=False)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hwlTWapZR8M",
    "outputId": "e2ced468-e4d8-497c-8f27-4262fba6eea1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '0000',\n",
       " '00000',\n",
       " '000000',\n",
       " '000005102000',\n",
       " '000021',\n",
       " '000062David42',\n",
       " '0000VEC',\n",
       " '0001']"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AYfpk0ds6Mij",
    "outputId": "a605ac46-771c-44cd-c5c9-0774625740d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 9)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min_df, max_df\n",
    "vectorizer = TfidfVectorizer(min_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ookt99atZ8sS",
    "outputId": "48acde37-ce1c-46e4-e131-bf3d99a36d4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'from', 'in', 'lines', 'of', 'organization', 'subject', 'the', 'to']"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e_h6c0X6Mim",
    "outputId": "1164d096-e211-478d-cb27-cc782b71690e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 2391)"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=0.01, max_df=0.8)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XUhOyx4NihL0",
    "outputId": "c5bdb88a-8a3b-4654-b0b4-9a8a5c79e132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1236)"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ngram_range\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), min_df=0.03, max_df=0.9)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "7074cdSF6MjC",
    "outputId": "378752c9-3ae1-436f-d3c5-568363006d90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'oh , think landed miracle work , thirst hunger come conference bird'"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# стоп-слова, preproc\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "\n",
    "def preproc_nltk(text):\n",
    "    #text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
    "    return ' '.join([wnl.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stopWords])\n",
    "\n",
    "st = \"Oh, I think I ve landed Where there are miracles at work,  For the thirst and for the hunger Come the conference of birds\"\n",
    "preproc_nltk(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LIW3hCSy6MjX",
    "outputId": "338c71af-0740-4c8f-c058-684dd087ad97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.19 s, sys: 12.1 ms, total: 8.2 s\n",
      "Wall time: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(preprocessor=preproc_nltk)\n",
    "vectors = vectorizer.fit_transform(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lUmyAzJEB1SU",
    "outputId": "f7b9009d-14f0-4436-e2e5-b7082f7aa6b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'oh , -PRON- think -PRON- land miracle work ,   thirst hunger come conference bird'"
      ]
     },
     "execution_count": 67,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preproc_spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "texts = newsgroups_train.data.copy()\n",
    "\n",
    "def preproc_spacy(text):\n",
    "    spacy_results = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in spacy_results if token.lemma_ not in stopWords])\n",
    "preproc_spacy(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0C5Ent0nG5zj",
    "outputId": "1af1abe9-bc09-480f-ced0-5caf77a7e0d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.7 s, sys: 426 ms, total: 33.1 s\n",
      "Wall time: 48.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_texts = []\n",
    "for doc in nlp.pipe(texts, batch_size=32, n_process=3, disable=[\"parser\", \"ner\"]):\n",
    "    new_texts.append(' '.join([tok.lemma_ for tok in doc if tok.lemma not in stopWords]))\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(new_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lXAPHZA6Mj0"
   },
   "source": [
    "#### Итоговая модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uZYcRkQ86Mj1",
    "outputId": "72392257-a3e9-405a-9238-169e7c0d115c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " 'au',\n",
       " 'christ',\n",
       " 'even',\n",
       " 'if pron have',\n",
       " 'matter',\n",
       " 'over',\n",
       " 'quote',\n",
       " 'still',\n",
       " 'truth']"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_df=0.5, max_features=1000)\n",
    "vectors = vectorizer.fit_transform(new_texts)\n",
    "vectorizer.get_feature_names()[::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQHTlj3q6Mj6"
   },
   "source": [
    "#### Можем посмотреть на косинусную меру между векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jo4fKtAXqCl-",
    "outputId": "81b8f469-e889-4c92-942e-63f0a526311d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 75,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VA8Fn5I46Mi0",
    "outputId": "632e1709-57eb-416c-f579-eaad32195408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = vectors.todense()[0]\n",
    "(vector != 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kweWqI8ztDwC",
    "outputId": "b729a5b3-fd07-4bc5-99fe-75909a02cd8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.63765978367748"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(list(map(lambda x: (x != 0).sum(), vectors.todense())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsVQhR9y6Mj8",
    "outputId": "378d430b-f6d2-4f76-e2d9-bda51d8479de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 76,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "type(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tS2G0ZZC6MkN",
    "outputId": "7dc5ec75-cf8e-4c15-a759-631dc63c6c57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2034, 1000)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_vectors = vectors.todense()\n",
    "dense_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LGgb5aP76MkU"
   },
   "outputs": [],
   "source": [
    "def cosine_sim(v1, v2):\n",
    "    # v1, v2 (1 x dim)\n",
    "    return np.array(v1 @ v2.T / norm(v1) / norm(v2))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_FrKM6k6MkY",
    "outputId": "462e7b13-1aa4-4506-e605-49feaf5ab150"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(dense_vectors[0], dense_vectors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1XF-isH6Mkh"
   },
   "outputs": [],
   "source": [
    "cosines = []\n",
    "for i in range(10):\n",
    "    cosines.append(cosine_sim(dense_vectors[0], dense_vectors[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ODwgYEbe6Mkl",
    "outputId": "b6959653-9dea-438a-9590-9c2afedceab4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0000000000000002,\n",
       " 0.043294587352860875,\n",
       " 0.005869835524491915,\n",
       " 0.0935800085948649,\n",
       " 0.042441093346628496,\n",
       " 0.04763556598669193,\n",
       " 0.038723466540658134,\n",
       " 0.22771527506874503,\n",
       " 0.03289646848736767,\n",
       " 0.06184884190504455]"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1, 3, 2, 0, 2, 0, 2, 1, 2, 1]\n",
    "cosines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRZyJP3c6Mkq"
   },
   "source": [
    "#### Обучим любую известную модель на полученных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RDfl72A6Mks",
    "outputId": "881d3b15-aa8b-479b-ce66-a06e91e47824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627,), (407,))"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(dense_vectors, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6EBZRbXT6Mly",
    "outputId": "1b992f83-1c25-4e3d-f536-b284d660e1e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8968058968058968"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, y_train)\n",
    "accuracy_score(y_test, sgd.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5OAwBJ0LuPb"
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKLGAYPvPJcJ"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "embeddings_pretrained = api.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmH3vc7FSCuP"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "proc_words = [preproc_nltk(text).split() for text in newsgroups_train.data]\n",
    "embeddings_trained = Word2Vec(proc_words, # data for model to train on\n",
    "                 size=100,                 # embedding vector size\n",
    "                 min_count=3,             # consider words that occured at least 5 times\n",
    "                 window=3).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Lq20widPJcO"
   },
   "outputs": [],
   "source": [
    "def vectorize_sum(comment, embeddings):\n",
    "    \"\"\"\n",
    "    implement a function that converts preprocessed comment to a sum of token vectors\n",
    "    \"\"\"\n",
    "    embedding_dim = embeddings.vectors.shape[1]\n",
    "    features = np.zeros([embedding_dim], dtype='float32')\n",
    "\n",
    "    for word in preproc_nltk(comment).split():\n",
    "        if word in embeddings:\n",
    "            features += embeddings[f'{word}']\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1KaMKBHsSHd",
    "outputId": "65336ef9-6d63-4c40-881d-d22ca4b8b2c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13651"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_trained.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "krjpVRsLPJcf",
    "outputId": "0f24b897-f3c5-4ee7-84fe-1ca5a2abeafe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627, 25), (407, 25))"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_pretrained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oWhQ007PPJcn",
    "outputId": "ba51dbd6-e7ef-4ed5-eac0-948d32f76a5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7100737100737101"
      ]
     },
     "execution_count": 96,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=5000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oT_Rr4nOUUu8",
    "outputId": "08a28d12-283e-4eab-d80c-6208cc6ceadd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1627, 100), (407, 100))"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_wv = np.stack([vectorize_sum(text, embeddings_trained) for text in newsgroups_train.data])\n",
    "X_train_wv, X_test_wv, y_train, y_test = train_test_split(X_wv, newsgroups_train.target, test_size=0.2, random_state=0)\n",
    "X_train_wv.shape, X_test_wv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uVMeZBLbVMjO",
    "outputId": "653442de-cfa8-4170-bfa6-1f87e00a6e29"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8402948402948403"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = LogisticRegression(max_iter=10000)\n",
    "wv_model = clf.fit(X_train_wv, y_train)\n",
    "accuracy_score(y_test, wv_model.predict(X_test_wv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
